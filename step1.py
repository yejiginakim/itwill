#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step 1 â€” Face Landmarks (MediaPipe FaceMesh)

ì—­í• : ì‚¬ì§„/í´ë”/ì›¹ìº /ë™ì˜ìƒì—ì„œ ì–¼êµ´ì„ íƒì§€í•˜ê³  468(ë˜ëŠ” 478)ê°œ ëœë“œë§ˆí¬ë¥¼ ì¶”ì¶œ.
ì‚°ì¶œë¬¼: CSV/JSON(í”½ì…€ ì¢Œí‘œ, ì •ê·œí™” ì¢Œí‘œ) + í•µì‹¬ í¬ì¸íŠ¸(ì–‘ëˆˆ ì¤‘ì‹¬, í„±ë, ëˆˆë™ì ë°˜ê²½ ë“±)

í™˜ê²½ ê¶Œì¥:
- mediapipe==0.10.21
- opencv-python>=4.9
- numpy>=1.24

ì‚¬ìš© ì˜ˆì‹œ:
1) ë‹¨ì¼ ì´ë¯¸ì§€ â†’ JSON/CSV ì €ì¥
   python step1_face_landmarks_mediapipe.py \
     --image '/path/to/face.jpg' \
     --out_dir './out_landmarks'

2) í´ë” ì¼ê´„ ì²˜ë¦¬ (jpg/png/webp)
   python step1_face_landmarks_mediapipe.py \
     --dir '/path/to/faces' \
     --out_dir './out_landmarks' \
     --exts jpg png webp

3) ë™ì˜ìƒ íŒŒì¼ì—ì„œ ì¶”ì¶œ(ë§¤ í”„ë ˆì„ ë˜ëŠ” Ní”„ë ˆì„ ê°„ê²© ì €ì¥)
   python step1_face_landmarks_mediapipe.py \
     --video '/path/to/video.mp4' \
     --out_dir './out_landmarks' \
     --frame_stride 5

4) ì›¹ìº  ë¯¸ë¦¬ë³´ê¸°(í‚¤ë³´ë“œ q ì¢…ë£Œ, së¡œ í˜„ì¬ í”„ë ˆì„ ì €ì¥)
   python step1_face_landmarks_mediapipe.py --webcam 0 --preview 1 --out_dir './out_landmarks'

ì¶œë ¥ íŒŒì¼:
- *_landmarks.json : ì „ì²´ ëœë“œë§ˆí¬(ì •ê·œí™”+í”½ì…€)
- *_landmarks.csv  : í”½ì…€ ì¢Œí‘œë§Œ í…Œì´ë¸”ë¡œ ì €ì¥
- *_preview.jpg    : ë¯¸ë¦¬ë³´ê¸°ìš© ëœë“œë§ˆí¬ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€(ì˜µì…˜)
"""

from __future__ import annotations
import argparse
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import cv2
import numpy as np

# MediaPipeëŠ” ëŸ°íƒ€ì„ ì‹œ import (ì„¤ì¹˜ê°€ ì•ˆ ëœ í™˜ê²½ì„ ìœ„í•´ ë©”ì‹œì§€ ì¹œì ˆí™”)
try:
    import mediapipe as mp
except Exception as e:  # pragma: no cover
    raise SystemExit('âŒ mediapipe import ì‹¤íŒ¨. `pip install mediapipe` í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.')

# ===== ìœ í‹¸ =====

def to_int_point(x: float, y: float) -> Tuple[int, int]:
    return int(round(x)), int(round(y))


def ensure_dir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)


# ===== FaceMesh Wrapper =====

class FaceMeshExtractor:
    def __init__(self,
                 static_image_mode: bool = True,
                 max_num_faces: int = 1,
                 refine_landmarks: bool = True,
                 min_detection_confidence: float = 0.5,
                 min_tracking_confidence: float = 0.5):
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            static_image_mode=static_image_mode,
            max_num_faces=max_num_faces,
            refine_landmarks=refine_landmarks,
            min_detection_confidence=min_detection_confidence,
            min_tracking_confidence=min_tracking_confidence,
        )
        self.draw = mp.solutions.drawing_utils
        self.styles = mp.solutions.drawing_styles

        # ì—°ê²° ì„¸íŠ¸(ìœ¤ê³½/ëˆˆ/ì… ë“±)
        self.CONN_TESSEL = self.mp_face_mesh.FACEMESH_TESSELATION
        self.CONN_CONTOURS = self.mp_face_mesh.FACEMESH_CONTOURS
        self.CONN_IRISES = getattr(self.mp_face_mesh, 'FACEMESH_IRISES', frozenset())

    def process_rgb(self, rgb: np.ndarray):
        return self.face_mesh.process(rgb)

    @staticmethod
    def _normalized_to_pixel(landmark, img_w: int, img_h: int) -> Tuple[float, float, float]:
        x = landmark.x * img_w
        y = landmark.y * img_h
        z = landmark.z  # zëŠ” ìƒëŒ€ê°’(ì¹´ë©”ë¼ì—ì„œì˜ ê¹Šì´ ìŠ¤ì¼€ì¼)
        return x, y, z

    def extract_from_image(self, bgr: np.ndarray) -> Optional[Dict]:
        if bgr is None:
            return None
        h, w = bgr.shape[:2]
        rgb = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)
        res = self.process_rgb(rgb)
        if not res.multi_face_landmarks:
            return None

        # ë‹¨ì¼ ì–¼êµ´ë§Œ ì‚¬ìš© (max_num_faces=1 ê¸°ë³¸)
        lms = res.multi_face_landmarks[0].landmark
        n = len(lms)
        px = np.zeros((n, 3), dtype=np.float32)
        for i, lm in enumerate(lms):
            px[i] = self._normalized_to_pixel(lm, w, h)

        out: Dict = {
            'image_width': int(w),
            'image_height': int(h),
            'num_landmarks': int(n),
            'landmarks_px': px.tolist(),  # [[x,y,z], ...]
            'landmarks_norm': [[float(lms[i].x), float(lms[i].y), float(lms[i].z)] for i in range(n)],
        }

        # ===== íŒŒìƒ íŠ¹ì§•(ëˆˆ ì¤‘ì‹¬/ë°˜ê²½, í„±ë ë“±) =====
        # refine_landmarks=True ì¼ ë•Œ í™ì±„(iris) 5í¬ì¸íŠ¸ì”© ì¶”ê°€ â†’ ì¤‘ì‹¬/ë°˜ê²½ ì¶”ì •ì— ìœ ë¦¬
        left_iris_ids = list(range(473, 478)) if n >= 478 else []
        right_iris_ids = list(range(468, 473)) if n >= 478 else []

        def mean_point(ids: List[int]) -> Optional[Tuple[float, float]]:
            if not ids:
                return None
            arr = px[ids, :2]
            return float(arr[:, 0].mean()), float(arr[:, 1].mean())

        def iris_radius(ids: List[int], center_xy: Tuple[float, float]) -> Optional[float]:
            if not ids or center_xy is None:
                return None
            cx, cy = center_xy
            arr = px[ids, :2]
            d = np.sqrt(((arr[:, 0] - cx) ** 2) + ((arr[:, 1] - cy) ** 2))
            return float(np.median(d))

        left_center = mean_point(left_iris_ids)
        right_center = mean_point(right_iris_ids)
        left_r = iris_radius(left_iris_ids, left_center) if left_center else None
        right_r = iris_radius(right_iris_ids, right_center) if right_center else None

        # í„±ë(ì¼ë°˜ì ìœ¼ë¡œ 152ë²ˆì´ í„±ëì— í•´ë‹¹)
        chin_idx = 152 if n > 152 else None
        chin_xy = None
        if chin_idx is not None:
            cx, cy = px[chin_idx, 0], px[chin_idx, 1]
            chin_xy = (float(cx), float(cy))

        # ì½” íŒ(ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ ë³´ìˆ˜ì ìœ¼ë¡œ ì„ íƒ)
        # ë°©ë²•: ì½” ì˜ì—­ ì¤‘ ì¹´ë©”ë¼ì— ê°€ì¥ ê°€ê¹Œìš´ ì (zê°€ ê°€ì¥ ì‘ì€)ì„ ì½”íŒ ê·¼ì‚¬ê°’ìœ¼ë¡œ ì‚¬ìš©
        nose_conns = getattr(self.mp_face_mesh, 'FACEMESH_NOSE', frozenset())
        nose_ids = sorted({i for pair in nose_conns for i in pair}) if nose_conns else list(range(1, min(20, n)))
        nose_tip_xy = None
        if nose_ids:
            zvals = px[nose_ids, 2]
            k = int(np.argmin(zvals))
            nose_tip_xy = (float(px[nose_ids[k], 0]), float(px[nose_ids[k], 1]))

        out['derived'] = {
            'left_iris_center_xy': left_center,
            'right_iris_center_xy': right_center,
            'left_iris_radius_px': left_r,
            'right_iris_radius_px': right_r,
            'chin_xy': chin_xy,
            'nose_tip_xy': nose_tip_xy,
        }
        return out

    def draw_overlay(self, bgr: np.ndarray, result_dict: Dict, draw_tessel: bool = False) -> np.ndarray:
        vis = bgr.copy()
        h, w = vis.shape[:2]

        # ëœë“œë§ˆí¬ ì  ì°ê¸°
        pts = np.array(result_dict['landmarks_px'], dtype=np.float32)
        for i in range(pts.shape[0]):
            x, y = to_int_point(pts[i, 0], pts[i, 1])
            cv2.circle(vis, (x, y), 1, (0, 255, 0), -1)

        # ì»¨íˆ¬ì–´/í™ì±„ ë¼ì¸(ì„ íƒ)
        if draw_tessel:
            # Tessellationì„ ì§ì ‘ ê·¸ë¦¬ë ¤ë©´ ì—°ê²° ì •ë³´ë¥¼ ì´ìš©í•´ ì„ ë¶„ì„ ê·¸ë¦¼
            for a, b in self.CONN_TESSEL:
                ax, ay = to_int_point(pts[a, 0], pts[a, 1])
                bx, by = to_int_point(pts[b, 0], pts[b, 1])
                cv2.line(vis, (ax, ay), (bx, by), (80, 80, 80), 1)

        # í•µì‹¬ í¬ì¸íŠ¸ ì‹œê°í™”
        d = result_dict.get('derived', {})
        def draw_keypoint(name: str, xy: Optional[Tuple[float, float]]):
            if not xy:
                return
            x, y = to_int_point(xy[0], xy[1])
            cv2.circle(vis, (x, y), 3, (0, 0, 255), -1)
            cv2.putText(vis, name, (x + 4, y - 4), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 1, cv2.LINE_AA)

        draw_keypoint('L_iris', d.get('left_iris_center_xy'))
        draw_keypoint('R_iris', d.get('right_iris_center_xy'))
        draw_keypoint('Chin', d.get('chin_xy'))
        draw_keypoint('Nose', d.get('nose_tip_xy'))

        return vis


# ===== I/O Helpers =====

def save_outputs(base: Path, result: Dict, save_preview: bool, bgr: Optional[np.ndarray] = None, extractor: Optional[FaceMeshExtractor] = None):
    base.parent.mkdir(parents=True, exist_ok=True)

    # JSON
    with open(base.with_suffix('.json'), 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    # CSV (í”½ì…€ì¢Œí‘œë§Œ)
    pts = np.array(result['landmarks_px'], dtype=np.float32)
    header = 'idx,x_px,y_px,z_rel\n'
    lines = [header] + [f'{i},{pts[i,0]:.3f},{pts[i,1]:.3f},{pts[i,2]:.5f}\n' for i in range(pts.shape[0])]
    with open(base.with_suffix('.csv'), 'w', encoding='utf-8') as f:
        f.writelines(lines)

    # Preview ì´ë¯¸ì§€
    if save_preview and bgr is not None and extractor is not None:
        vis = extractor.draw_overlay(bgr, result, draw_tessel=False)
        cv2.imwrite(str(base.with_suffix('.preview.jpg')), vis)


# ===== ë©”ì¸ íŒŒì´í”„ë¼ì¸ =====

def process_image_file(img_path: Path, out_dir: Path, extractor: FaceMeshExtractor, save_preview: bool = True) -> Optional[Path]:
    bgr = cv2.imread(str(img_path))
    if bgr is None:
        print(f'âš ï¸  ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}')
        return None
    res = extractor.extract_from_image(bgr)
    if res is None:
        print(f'âš ï¸  ì–¼êµ´ ë¯¸ê²€ì¶œ: {img_path}')
        return None
    base = out_dir / f'{img_path.stem}_landmarks'
    save_outputs(base, res, save_preview=save_preview, bgr=bgr, extractor=extractor)
    print(f'âœ… ì €ì¥: {base.with_suffix(".json").name}, {base.with_suffix(".csv").name}')
    return base


def process_dir(dir_path: Path, out_dir: Path, exts: List[str], extractor: FaceMeshExtractor, save_preview: bool = True):
    patterns = [f'**/*.{ext.lower()}' for ext in exts]
    files: List[Path] = []
    for pat in patterns:
        files.extend(sorted(dir_path.glob(pat)))

    if not files:
        print('âš ï¸  ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.')
        return
    for p in files:
        process_image_file(p, out_dir, extractor, save_preview=save_preview)


def process_video(video_path: Path, out_dir: Path, extractor: FaceMeshExtractor, frame_stride: int = 1, save_preview: bool = False):
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise SystemExit(f'âŒ ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {video_path}')

    idx = 0
    saved = 0
    ensure_dir(out_dir)

    while True:
        ok, frame = cap.read()
        if not ok:
            break
        if idx % max(1, frame_stride) != 0:
            idx += 1
            continue
        res = extractor.extract_from_image(frame)
        if res:
            frame_name = f'{video_path.stem}_f{idx:06d}_landmarks'
            base = out_dir / frame_name
            save_outputs(base, res, save_preview=save_preview, bgr=frame, extractor=extractor)
            saved += 1
        idx += 1
    cap.release()
    print(f'âœ… í”„ë ˆì„ ì €ì¥ ìˆ˜: {saved}')


def run_webcam(cam_index: int, extractor: FaceMeshExtractor, preview: bool, out_dir: Optional[Path] = None):
    cap = cv2.VideoCapture(int(cam_index))
    if not cap.isOpened():
        raise SystemExit('âŒ ì›¹ìº  ì—´ê¸° ì‹¤íŒ¨')

    ensure_dir(out_dir) if out_dir else None
    print("[q] ì¢…ë£Œ, [s] í˜„ì¬ í”„ë ˆì„ ì €ì¥")

    while True:
        ok, frame = cap.read()
        if not ok:
            break
        res = extractor.extract_from_image(frame)
        vis = frame.copy()
        if res:
            vis = extractor.draw_overlay(frame, res, draw_tessel=False)
        cv2.imshow('FaceMesh', vis if preview else frame)
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        if key == ord('s') and res and out_dir:
            base = out_dir / 'webcam_snapshot_landmarks'
            save_outputs(base, res, save_preview=True, bgr=frame, extractor=extractor)
            print('ğŸ’¾ ìŠ¤ëƒ…ìƒ· ì €ì¥')

    cap.release()
    cv2.destroyAllWindows()


# ===== CLI =====

def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description='MediaPipe FaceMesh Landmarks Extractor')
    p.add_argument('--image', type=str, help='ë‹¨ì¼ ì´ë¯¸ì§€ ê²½ë¡œ')
    p.add_argument('--dir', type=str, help='ì¼ê´„ ì²˜ë¦¬í•  í´ë” ê²½ë¡œ')
    p.add_argument('--exts', nargs='*', default=['jpg', 'jpeg', 'png', 'webp'], help='í´ë” ì²˜ë¦¬ ì‹œ í—ˆìš© í™•ì¥ì')
    p.add_argument('--video', type=str, help='ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œ')
    p.add_argument('--frame_stride', type=int, default=1, help='ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œ í”„ë ˆì„ ê°„ê²©')
    p.add_argument('--webcam', type=int, help='ì›¹ìº  ì¸ë±ìŠ¤ (ì˜ˆ: 0)')
    p.add_argument('--preview', type=int, default=1, help='ë¯¸ë¦¬ë³´ê¸° ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸° (1/0)')
    p.add_argument('--out_dir', type=str, default='./out_landmarks', help='ì¶œë ¥ í´ë”')
    p.add_argument('--static', type=int, default=1, help='static_image_mode (1=ì •ì§€ ì´ë¯¸ì§€, 0=ìŠ¤íŠ¸ë¦¬ë°)')
    p.add_argument('--max_faces', type=int, default=1, help='ìµœëŒ€ ì–¼êµ´ ìˆ˜')
    p.add_argument('--refine', type=int, default=1, help='refine_landmarks (í™ì±„ í¬í•¨)')
    p.add_argument('--det_conf', type=float, default=0.5, help='min_detection_confidence')
    p.add_argument('--trk_conf', type=float, default=0.5, help='min_tracking_confidence')
    return p.parse_args()


def main():
    args = parse_args()

    out_dir = Path(args.out_dir)
    ensure_dir(out_dir)

    extractor = FaceMeshExtractor(
        static_image_mode=bool(args.static),
        max_num_faces=int(args.max_faces),
        refine_landmarks=bool(args.refine),
        min_detection_confidence=float(args.det_conf),
        min_tracking_confidence=float(args.trk_conf),
    )  

    has_job = False
    if args.image:
        has_job = True
        process_image_file(Path(args.image), out_dir, extractor, save_preview=bool(args.preview))

    if args.dir:
        has_job = True
        process_dir(Path(args.dir), out_dir, [ext.lower() for ext in args.exts], extractor, save_preview=bool(args.preview))

    if args.video:
        has_job = True
        process_video(Path(args.video), out_dir, extractor, frame_stride=int(args.frame_stride), save_preview=bool(args.preview))

    if args.webcam is not None:
        has_job = True
        run_webcam(int(args.webcam), extractor, preview=bool(args.preview), out_dir=out_dir)

    if not has_job:
        print('ì•„ë˜ ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•˜ì„¸ìš”: --image, --dir, --video, --webcam')


if __name__ == '__main__':
    main()
